{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitToEmoji-GIT.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        "\n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment\n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07523d4f-b5ed-488d-8279-3421d89f974a"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "2ae2c4af-c275-4d39-e600-2441ef457da7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "\n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.12.0\n",
            "\n",
            "\u001b[32;4mamarillo\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "100 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4mcafe\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "100 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4mverde\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "100 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c456e0-f91c-4de3-a3f6-697f3cb8c298"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "45/45 [==============================] - 1s 7ms/step - loss: 0.2207 - mae: 0.4428 - val_loss: 0.2211 - val_mae: 0.4432\n",
            "Epoch 2/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2201 - mae: 0.4421 - val_loss: 0.2210 - val_mae: 0.4431\n",
            "Epoch 3/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2197 - mae: 0.4417 - val_loss: 0.2210 - val_mae: 0.4430\n",
            "Epoch 4/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2192 - mae: 0.4411 - val_loss: 0.2209 - val_mae: 0.4428\n",
            "Epoch 5/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2188 - mae: 0.4407 - val_loss: 0.2209 - val_mae: 0.4427\n",
            "Epoch 6/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2183 - mae: 0.4400 - val_loss: 0.2207 - val_mae: 0.4425\n",
            "Epoch 7/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2178 - mae: 0.4394 - val_loss: 0.2205 - val_mae: 0.4422\n",
            "Epoch 8/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2173 - mae: 0.4389 - val_loss: 0.2204 - val_mae: 0.4419\n",
            "Epoch 9/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2169 - mae: 0.4382 - val_loss: 0.2200 - val_mae: 0.4414\n",
            "Epoch 10/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2164 - mae: 0.4376 - val_loss: 0.2199 - val_mae: 0.4412\n",
            "Epoch 11/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2157 - mae: 0.4370 - val_loss: 0.2193 - val_mae: 0.4405\n",
            "Epoch 12/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2153 - mae: 0.4365 - val_loss: 0.2189 - val_mae: 0.4401\n",
            "Epoch 13/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2147 - mae: 0.4357 - val_loss: 0.2179 - val_mae: 0.4392\n",
            "Epoch 14/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2140 - mae: 0.4352 - val_loss: 0.2174 - val_mae: 0.4385\n",
            "Epoch 15/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2133 - mae: 0.4343 - val_loss: 0.2164 - val_mae: 0.4375\n",
            "Epoch 16/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2126 - mae: 0.4336 - val_loss: 0.2159 - val_mae: 0.4369\n",
            "Epoch 17/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2117 - mae: 0.4328 - val_loss: 0.2154 - val_mae: 0.4362\n",
            "Epoch 18/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2109 - mae: 0.4316 - val_loss: 0.2139 - val_mae: 0.4347\n",
            "Epoch 19/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2100 - mae: 0.4305 - val_loss: 0.2122 - val_mae: 0.4333\n",
            "Epoch 20/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2088 - mae: 0.4297 - val_loss: 0.2120 - val_mae: 0.4327\n",
            "Epoch 21/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2077 - mae: 0.4283 - val_loss: 0.2098 - val_mae: 0.4306\n",
            "Epoch 22/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2065 - mae: 0.4270 - val_loss: 0.2080 - val_mae: 0.4289\n",
            "Epoch 23/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2051 - mae: 0.4256 - val_loss: 0.2066 - val_mae: 0.4274\n",
            "Epoch 24/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2034 - mae: 0.4240 - val_loss: 0.2065 - val_mae: 0.4267\n",
            "Epoch 25/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2025 - mae: 0.4228 - val_loss: 0.2030 - val_mae: 0.4235\n",
            "Epoch 26/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2007 - mae: 0.4209 - val_loss: 0.2018 - val_mae: 0.4220\n",
            "Epoch 27/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1990 - mae: 0.4191 - val_loss: 0.1990 - val_mae: 0.4193\n",
            "Epoch 28/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1975 - mae: 0.4174 - val_loss: 0.1970 - val_mae: 0.4171\n",
            "Epoch 29/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1955 - mae: 0.4151 - val_loss: 0.1940 - val_mae: 0.4142\n",
            "Epoch 30/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1937 - mae: 0.4133 - val_loss: 0.1924 - val_mae: 0.4121\n",
            "Epoch 31/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1917 - mae: 0.4114 - val_loss: 0.1914 - val_mae: 0.4106\n",
            "Epoch 32/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1899 - mae: 0.4091 - val_loss: 0.1870 - val_mae: 0.4062\n",
            "Epoch 33/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1875 - mae: 0.4064 - val_loss: 0.1836 - val_mae: 0.4025\n",
            "Epoch 34/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1853 - mae: 0.4037 - val_loss: 0.1809 - val_mae: 0.3992\n",
            "Epoch 35/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1828 - mae: 0.4010 - val_loss: 0.1776 - val_mae: 0.3954\n",
            "Epoch 36/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1803 - mae: 0.3978 - val_loss: 0.1745 - val_mae: 0.3917\n",
            "Epoch 37/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1778 - mae: 0.3949 - val_loss: 0.1713 - val_mae: 0.3878\n",
            "Epoch 38/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1751 - mae: 0.3915 - val_loss: 0.1681 - val_mae: 0.3837\n",
            "Epoch 39/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1725 - mae: 0.3882 - val_loss: 0.1651 - val_mae: 0.3798\n",
            "Epoch 40/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1698 - mae: 0.3848 - val_loss: 0.1632 - val_mae: 0.3770\n",
            "Epoch 41/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1669 - mae: 0.3809 - val_loss: 0.1595 - val_mae: 0.3721\n",
            "Epoch 42/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1643 - mae: 0.3774 - val_loss: 0.1568 - val_mae: 0.3684\n",
            "Epoch 43/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1615 - mae: 0.3735 - val_loss: 0.1528 - val_mae: 0.3630\n",
            "Epoch 44/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1587 - mae: 0.3696 - val_loss: 0.1495 - val_mae: 0.3583\n",
            "Epoch 45/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1556 - mae: 0.3650 - val_loss: 0.1452 - val_mae: 0.3522\n",
            "Epoch 46/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1530 - mae: 0.3612 - val_loss: 0.1422 - val_mae: 0.3477\n",
            "Epoch 47/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1499 - mae: 0.3567 - val_loss: 0.1389 - val_mae: 0.3426\n",
            "Epoch 48/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1473 - mae: 0.3525 - val_loss: 0.1365 - val_mae: 0.3385\n",
            "Epoch 49/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1447 - mae: 0.3484 - val_loss: 0.1346 - val_mae: 0.3353\n",
            "Epoch 50/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1418 - mae: 0.3436 - val_loss: 0.1301 - val_mae: 0.3282\n",
            "Epoch 51/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1391 - mae: 0.3392 - val_loss: 0.1269 - val_mae: 0.3225\n",
            "Epoch 52/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1363 - mae: 0.3346 - val_loss: 0.1241 - val_mae: 0.3177\n",
            "Epoch 53/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.3301 - val_loss: 0.1204 - val_mae: 0.3109\n",
            "Epoch 54/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1313 - mae: 0.3254 - val_loss: 0.1178 - val_mae: 0.3060\n",
            "Epoch 55/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1288 - mae: 0.3206 - val_loss: 0.1152 - val_mae: 0.3008\n",
            "Epoch 56/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1262 - mae: 0.3156 - val_loss: 0.1129 - val_mae: 0.2963\n",
            "Epoch 57/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1234 - mae: 0.3106 - val_loss: 0.1102 - val_mae: 0.2902\n",
            "Epoch 58/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1217 - mae: 0.3066 - val_loss: 0.1073 - val_mae: 0.2840\n",
            "Epoch 59/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1195 - mae: 0.3019 - val_loss: 0.1053 - val_mae: 0.2801\n",
            "Epoch 60/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1172 - mae: 0.2973 - val_loss: 0.1025 - val_mae: 0.2735\n",
            "Epoch 61/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1153 - mae: 0.2929 - val_loss: 0.1005 - val_mae: 0.2689\n",
            "Epoch 62/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1133 - mae: 0.2886 - val_loss: 0.0986 - val_mae: 0.2643\n",
            "Epoch 63/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1114 - mae: 0.2843 - val_loss: 0.0969 - val_mae: 0.2594\n",
            "Epoch 64/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1099 - mae: 0.2805 - val_loss: 0.0956 - val_mae: 0.2573\n",
            "Epoch 65/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.2760 - val_loss: 0.0940 - val_mae: 0.2537\n",
            "Epoch 66/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1066 - mae: 0.2727 - val_loss: 0.0922 - val_mae: 0.2488\n",
            "Epoch 67/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1043 - mae: 0.2680 - val_loss: 0.0911 - val_mae: 0.2460\n",
            "Epoch 68/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1032 - mae: 0.2645 - val_loss: 0.0888 - val_mae: 0.2400\n",
            "Epoch 69/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1017 - mae: 0.2611 - val_loss: 0.0873 - val_mae: 0.2351\n",
            "Epoch 70/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1001 - mae: 0.2576 - val_loss: 0.0868 - val_mae: 0.2348\n",
            "Epoch 71/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0988 - mae: 0.2543 - val_loss: 0.0846 - val_mae: 0.2290\n",
            "Epoch 72/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 0.2516 - val_loss: 0.0832 - val_mae: 0.2247\n",
            "Epoch 73/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0961 - mae: 0.2482 - val_loss: 0.0818 - val_mae: 0.2209\n",
            "Epoch 74/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0938 - mae: 0.2439 - val_loss: 0.0811 - val_mae: 0.2185\n",
            "Epoch 75/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0935 - mae: 0.2421 - val_loss: 0.0795 - val_mae: 0.2156\n",
            "Epoch 76/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0913 - mae: 0.2385 - val_loss: 0.0782 - val_mae: 0.2134\n",
            "Epoch 77/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0899 - mae: 0.2356 - val_loss: 0.0768 - val_mae: 0.2091\n",
            "Epoch 78/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0886 - mae: 0.2329 - val_loss: 0.0759 - val_mae: 0.2063\n",
            "Epoch 79/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0878 - mae: 0.2310 - val_loss: 0.0743 - val_mae: 0.2045\n",
            "Epoch 80/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0858 - mae: 0.2275 - val_loss: 0.0728 - val_mae: 0.2016\n",
            "Epoch 81/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0843 - mae: 0.2246 - val_loss: 0.0720 - val_mae: 0.2008\n",
            "Epoch 82/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0833 - mae: 0.2228 - val_loss: 0.0710 - val_mae: 0.1994\n",
            "Epoch 83/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0818 - mae: 0.2203 - val_loss: 0.0709 - val_mae: 0.1987\n",
            "Epoch 84/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0801 - mae: 0.2177 - val_loss: 0.0683 - val_mae: 0.1914\n",
            "Epoch 85/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0796 - mae: 0.2159 - val_loss: 0.0666 - val_mae: 0.1901\n",
            "Epoch 86/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0779 - mae: 0.2134 - val_loss: 0.0655 - val_mae: 0.1881\n",
            "Epoch 87/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0761 - mae: 0.2105 - val_loss: 0.0642 - val_mae: 0.1861\n",
            "Epoch 88/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0748 - mae: 0.2085 - val_loss: 0.0630 - val_mae: 0.1826\n",
            "Epoch 89/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0725 - mae: 0.2049 - val_loss: 0.0615 - val_mae: 0.1812\n",
            "Epoch 90/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0712 - mae: 0.2028 - val_loss: 0.0603 - val_mae: 0.1775\n",
            "Epoch 91/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0699 - mae: 0.2004 - val_loss: 0.0584 - val_mae: 0.1757\n",
            "Epoch 92/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0679 - mae: 0.1969 - val_loss: 0.0572 - val_mae: 0.1729\n",
            "Epoch 93/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0665 - mae: 0.1949 - val_loss: 0.0568 - val_mae: 0.1741\n",
            "Epoch 94/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0653 - mae: 0.1932 - val_loss: 0.0544 - val_mae: 0.1683\n",
            "Epoch 95/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0637 - mae: 0.1905 - val_loss: 0.0532 - val_mae: 0.1670\n",
            "Epoch 96/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0613 - mae: 0.1862 - val_loss: 0.0511 - val_mae: 0.1635\n",
            "Epoch 97/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0591 - mae: 0.1835 - val_loss: 0.0500 - val_mae: 0.1601\n",
            "Epoch 98/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0576 - mae: 0.1806 - val_loss: 0.0488 - val_mae: 0.1598\n",
            "Epoch 99/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0553 - mae: 0.1769 - val_loss: 0.0470 - val_mae: 0.1546\n",
            "Epoch 100/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0534 - mae: 0.1736 - val_loss: 0.0445 - val_mae: 0.1515\n",
            "Epoch 101/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.1710 - val_loss: 0.0437 - val_mae: 0.1509\n",
            "Epoch 102/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0500 - mae: 0.1679 - val_loss: 0.0415 - val_mae: 0.1466\n",
            "Epoch 103/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0486 - mae: 0.1654 - val_loss: 0.0415 - val_mae: 0.1469\n",
            "Epoch 104/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1617 - val_loss: 0.0389 - val_mae: 0.1409\n",
            "Epoch 105/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0435 - mae: 0.1564 - val_loss: 0.0377 - val_mae: 0.1393\n",
            "Epoch 106/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0436 - mae: 0.1562 - val_loss: 0.0359 - val_mae: 0.1361\n",
            "Epoch 107/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.1522 - val_loss: 0.0344 - val_mae: 0.1326\n",
            "Epoch 108/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0398 - mae: 0.1494 - val_loss: 0.0329 - val_mae: 0.1305\n",
            "Epoch 109/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1467 - val_loss: 0.0318 - val_mae: 0.1284\n",
            "Epoch 110/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0364 - mae: 0.1429 - val_loss: 0.0302 - val_mae: 0.1254\n",
            "Epoch 111/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.1396 - val_loss: 0.0289 - val_mae: 0.1217\n",
            "Epoch 112/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0335 - mae: 0.1371 - val_loss: 0.0275 - val_mae: 0.1199\n",
            "Epoch 113/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1335 - val_loss: 0.0259 - val_mae: 0.1161\n",
            "Epoch 114/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.1300 - val_loss: 0.0246 - val_mae: 0.1131\n",
            "Epoch 115/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1263 - val_loss: 0.0231 - val_mae: 0.1101\n",
            "Epoch 116/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.1222 - val_loss: 0.0221 - val_mae: 0.1075\n",
            "Epoch 117/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.1190 - val_loss: 0.0206 - val_mae: 0.1038\n",
            "Epoch 118/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0240 - mae: 0.1165 - val_loss: 0.0194 - val_mae: 0.1009\n",
            "Epoch 119/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0223 - mae: 0.1119 - val_loss: 0.0185 - val_mae: 0.0986\n",
            "Epoch 120/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0212 - mae: 0.1096 - val_loss: 0.0173 - val_mae: 0.0954\n",
            "Epoch 121/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.1069 - val_loss: 0.0164 - val_mae: 0.0933\n",
            "Epoch 122/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1029 - val_loss: 0.0155 - val_mae: 0.0899\n",
            "Epoch 123/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1006 - val_loss: 0.0147 - val_mae: 0.0883\n",
            "Epoch 124/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.0977 - val_loss: 0.0136 - val_mae: 0.0853\n",
            "Epoch 125/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0943 - val_loss: 0.0135 - val_mae: 0.0847\n",
            "Epoch 126/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0915 - val_loss: 0.0119 - val_mae: 0.0796\n",
            "Epoch 127/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0882 - val_loss: 0.0115 - val_mae: 0.0783\n",
            "Epoch 128/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0854 - val_loss: 0.0106 - val_mae: 0.0756\n",
            "Epoch 129/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0817 - val_loss: 0.0101 - val_mae: 0.0725\n",
            "Epoch 130/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0791 - val_loss: 0.0092 - val_mae: 0.0706\n",
            "Epoch 131/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0760 - val_loss: 0.0080 - val_mae: 0.0663\n",
            "Epoch 132/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0727 - val_loss: 0.0075 - val_mae: 0.0640\n",
            "Epoch 133/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0703 - val_loss: 0.0069 - val_mae: 0.0613\n",
            "Epoch 134/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0671 - val_loss: 0.0066 - val_mae: 0.0594\n",
            "Epoch 135/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0643 - val_loss: 0.0057 - val_mae: 0.0567\n",
            "Epoch 136/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0618 - val_loss: 0.0052 - val_mae: 0.0545\n",
            "Epoch 137/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0588 - val_loss: 0.0047 - val_mae: 0.0514\n",
            "Epoch 138/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0554 - val_loss: 0.0045 - val_mae: 0.0504\n",
            "Epoch 139/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0533 - val_loss: 0.0040 - val_mae: 0.0475\n",
            "Epoch 140/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0520 - val_loss: 0.0037 - val_mae: 0.0462\n",
            "Epoch 141/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0035 - val_mae: 0.0441\n",
            "Epoch 142/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0033 - val_mae: 0.0425\n",
            "Epoch 143/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0029 - val_mae: 0.0412\n",
            "Epoch 144/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0027 - val_mae: 0.0393\n",
            "Epoch 145/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0023 - val_mae: 0.0364\n",
            "Epoch 146/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 0.0021 - val_mae: 0.0356\n",
            "Epoch 147/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0377 - val_loss: 0.0020 - val_mae: 0.0342\n",
            "Epoch 148/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 0.0018 - val_mae: 0.0323\n",
            "Epoch 149/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0338 - val_loss: 0.0016 - val_mae: 0.0310\n",
            "Epoch 150/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 151/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 152/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0269\n",
            "Epoch 153/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 154/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0246\n",
            "Epoch 155/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0255 - val_loss: 8.3202e-04 - val_mae: 0.0231\n",
            "Epoch 156/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.0735e-04 - mae: 0.0243 - val_loss: 7.7816e-04 - val_mae: 0.0223\n",
            "Epoch 157/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.2135e-04 - mae: 0.0233 - val_loss: 7.4684e-04 - val_mae: 0.0218\n",
            "Epoch 158/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 7.5734e-04 - mae: 0.0224 - val_loss: 6.8444e-04 - val_mae: 0.0206\n",
            "Epoch 159/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.7950e-04 - mae: 0.0212 - val_loss: 5.7170e-04 - val_mae: 0.0194\n",
            "Epoch 160/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.2637e-04 - mae: 0.0203 - val_loss: 5.6564e-04 - val_mae: 0.0192\n",
            "Epoch 161/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.6187e-04 - mae: 0.0193 - val_loss: 5.3599e-04 - val_mae: 0.0184\n",
            "Epoch 162/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.2298e-04 - mae: 0.0187 - val_loss: 5.2459e-04 - val_mae: 0.0183\n",
            "Epoch 163/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 4.7879e-04 - mae: 0.0180 - val_loss: 4.1438e-04 - val_mae: 0.0166\n",
            "Epoch 164/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 4.4596e-04 - mae: 0.0173 - val_loss: 3.7890e-04 - val_mae: 0.0159\n",
            "Epoch 165/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.1641e-04 - mae: 0.0168 - val_loss: 3.7040e-04 - val_mae: 0.0158\n",
            "Epoch 166/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.6938e-04 - mae: 0.0159 - val_loss: 3.8468e-04 - val_mae: 0.0156\n",
            "Epoch 167/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.4767e-04 - mae: 0.0154 - val_loss: 3.0353e-04 - val_mae: 0.0144\n",
            "Epoch 168/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.2656e-04 - mae: 0.0150 - val_loss: 2.9075e-04 - val_mae: 0.0140\n",
            "Epoch 169/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9499e-04 - mae: 0.0142 - val_loss: 2.6158e-04 - val_mae: 0.0134\n",
            "Epoch 170/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7750e-04 - mae: 0.0138 - val_loss: 2.4073e-04 - val_mae: 0.0129\n",
            "Epoch 171/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.5887e-04 - mae: 0.0134 - val_loss: 2.6569e-04 - val_mae: 0.0131\n",
            "Epoch 172/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3822e-04 - mae: 0.0128 - val_loss: 2.1891e-04 - val_mae: 0.0121\n",
            "Epoch 173/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.2094e-04 - mae: 0.0124 - val_loss: 1.9671e-04 - val_mae: 0.0116\n",
            "Epoch 174/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.9961e-04 - mae: 0.0118 - val_loss: 1.8402e-04 - val_mae: 0.0112\n",
            "Epoch 175/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.9319e-04 - mae: 0.0116 - val_loss: 1.9371e-04 - val_mae: 0.0112\n",
            "Epoch 176/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7865e-04 - mae: 0.0111 - val_loss: 1.6847e-04 - val_mae: 0.0108\n",
            "Epoch 177/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7122e-04 - mae: 0.0109 - val_loss: 1.6095e-04 - val_mae: 0.0104\n",
            "Epoch 178/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.6163e-04 - mae: 0.0106 - val_loss: 1.4095e-04 - val_mae: 0.0099\n",
            "Epoch 179/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.5122e-04 - mae: 0.0103 - val_loss: 1.3398e-04 - val_mae: 0.0096\n",
            "Epoch 180/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.4073e-04 - mae: 0.0099 - val_loss: 1.2787e-04 - val_mae: 0.0095\n",
            "Epoch 181/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.3583e-04 - mae: 0.0098 - val_loss: 1.1889e-04 - val_mae: 0.0091\n",
            "Epoch 182/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2637e-04 - mae: 0.0094 - val_loss: 1.3123e-04 - val_mae: 0.0093\n",
            "Epoch 183/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.1963e-04 - mae: 0.0091 - val_loss: 1.1188e-04 - val_mae: 0.0088\n",
            "Epoch 184/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.1554e-04 - mae: 0.0090 - val_loss: 1.1046e-04 - val_mae: 0.0086\n",
            "Epoch 185/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0661e-04 - mae: 0.0087 - val_loss: 9.6194e-05 - val_mae: 0.0082\n",
            "Epoch 186/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0373e-04 - mae: 0.0086 - val_loss: 1.0612e-04 - val_mae: 0.0084\n",
            "Epoch 187/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.5502e-05 - mae: 0.0082 - val_loss: 8.9274e-05 - val_mae: 0.0079\n",
            "Epoch 188/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 9.3035e-05 - mae: 0.0081 - val_loss: 8.3404e-05 - val_mae: 0.0076\n",
            "Epoch 189/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 8.7012e-05 - mae: 0.0078 - val_loss: 8.1803e-05 - val_mae: 0.0076\n",
            "Epoch 190/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.3491e-05 - mae: 0.0076 - val_loss: 7.7980e-05 - val_mae: 0.0074\n",
            "Epoch 191/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 7.8194e-05 - mae: 0.0075 - val_loss: 7.3400e-05 - val_mae: 0.0071\n",
            "Epoch 192/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.5976e-05 - mae: 0.0073 - val_loss: 7.4122e-05 - val_mae: 0.0071\n",
            "Epoch 193/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 7.0798e-05 - mae: 0.0070 - val_loss: 6.5136e-05 - val_mae: 0.0068\n",
            "Epoch 194/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.9143e-05 - mae: 0.0070 - val_loss: 6.2901e-05 - val_mae: 0.0066\n",
            "Epoch 195/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.4423e-05 - mae: 0.0067 - val_loss: 6.1894e-05 - val_mae: 0.0066\n",
            "Epoch 196/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.2458e-05 - mae: 0.0066 - val_loss: 5.8112e-05 - val_mae: 0.0064\n",
            "Epoch 197/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.9957e-05 - mae: 0.0065 - val_loss: 5.7727e-05 - val_mae: 0.0063\n",
            "Epoch 198/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.7579e-05 - mae: 0.0063 - val_loss: 5.4122e-05 - val_mae: 0.0061\n",
            "Epoch 199/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.5706e-05 - mae: 0.0062 - val_loss: 5.2679e-05 - val_mae: 0.0060\n",
            "Epoch 200/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.1338e-05 - mae: 0.0060 - val_loss: 5.2951e-05 - val_mae: 0.0060\n",
            "Epoch 201/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.1284e-05 - mae: 0.0060 - val_loss: 5.3480e-05 - val_mae: 0.0060\n",
            "Epoch 202/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.9898e-05 - mae: 0.0059 - val_loss: 4.7408e-05 - val_mae: 0.0057\n",
            "Epoch 203/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.6829e-05 - mae: 0.0058 - val_loss: 5.1339e-05 - val_mae: 0.0058\n",
            "Epoch 204/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.4612e-05 - mae: 0.0056 - val_loss: 4.2164e-05 - val_mae: 0.0054\n",
            "Epoch 205/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.3174e-05 - mae: 0.0055 - val_loss: 3.9687e-05 - val_mae: 0.0053\n",
            "Epoch 206/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.0044e-05 - mae: 0.0053 - val_loss: 3.8834e-05 - val_mae: 0.0052\n",
            "Epoch 207/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.9125e-05 - mae: 0.0053 - val_loss: 3.8743e-05 - val_mae: 0.0052\n",
            "Epoch 208/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.7573e-05 - mae: 0.0052 - val_loss: 3.4798e-05 - val_mae: 0.0049\n",
            "Epoch 209/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.6045e-05 - mae: 0.0051 - val_loss: 4.0549e-05 - val_mae: 0.0052\n",
            "Epoch 210/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.5712e-05 - mae: 0.0050 - val_loss: 3.5266e-05 - val_mae: 0.0049\n",
            "Epoch 211/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.3789e-05 - mae: 0.0049 - val_loss: 3.1898e-05 - val_mae: 0.0047\n",
            "Epoch 212/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.1818e-05 - mae: 0.0047 - val_loss: 3.1510e-05 - val_mae: 0.0047\n",
            "Epoch 213/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.0781e-05 - mae: 0.0047 - val_loss: 3.0111e-05 - val_mae: 0.0046\n",
            "Epoch 214/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.9959e-05 - mae: 0.0046 - val_loss: 2.9061e-05 - val_mae: 0.0045\n",
            "Epoch 215/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.8469e-05 - mae: 0.0045 - val_loss: 3.0052e-05 - val_mae: 0.0045\n",
            "Epoch 216/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7483e-05 - mae: 0.0044 - val_loss: 2.8194e-05 - val_mae: 0.0044\n",
            "Epoch 217/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7124e-05 - mae: 0.0044 - val_loss: 2.5123e-05 - val_mae: 0.0042\n",
            "Epoch 218/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5517e-05 - mae: 0.0042 - val_loss: 2.4694e-05 - val_mae: 0.0041\n",
            "Epoch 219/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4739e-05 - mae: 0.0042 - val_loss: 2.3502e-05 - val_mae: 0.0041\n",
            "Epoch 220/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3873e-05 - mae: 0.0041 - val_loss: 2.2702e-05 - val_mae: 0.0040\n",
            "Epoch 221/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3807e-05 - mae: 0.0041 - val_loss: 2.3440e-05 - val_mae: 0.0040\n",
            "Epoch 222/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.2195e-05 - mae: 0.0040 - val_loss: 2.2182e-05 - val_mae: 0.0039\n",
            "Epoch 223/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.1798e-05 - mae: 0.0039 - val_loss: 2.1209e-05 - val_mae: 0.0038\n",
            "Epoch 224/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.1058e-05 - mae: 0.0039 - val_loss: 2.0049e-05 - val_mae: 0.0038\n",
            "Epoch 225/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0362e-05 - mae: 0.0038 - val_loss: 1.9653e-05 - val_mae: 0.0037\n",
            "Epoch 226/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.0006e-05 - mae: 0.0038 - val_loss: 1.8950e-05 - val_mae: 0.0036\n",
            "Epoch 227/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.9097e-05 - mae: 0.0037 - val_loss: 1.9068e-05 - val_mae: 0.0036\n",
            "Epoch 228/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.8639e-05 - mae: 0.0036 - val_loss: 1.7715e-05 - val_mae: 0.0035\n",
            "Epoch 229/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8631e-05 - mae: 0.0036 - val_loss: 1.7294e-05 - val_mae: 0.0035\n",
            "Epoch 230/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7375e-05 - mae: 0.0035 - val_loss: 1.7160e-05 - val_mae: 0.0034\n",
            "Epoch 231/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7138e-05 - mae: 0.0035 - val_loss: 1.6246e-05 - val_mae: 0.0034\n",
            "Epoch 232/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6412e-05 - mae: 0.0034 - val_loss: 1.6679e-05 - val_mae: 0.0034\n",
            "Epoch 233/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5802e-05 - mae: 0.0033 - val_loss: 1.6763e-05 - val_mae: 0.0034\n",
            "Epoch 234/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5825e-05 - mae: 0.0034 - val_loss: 1.5497e-05 - val_mae: 0.0033\n",
            "Epoch 235/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5108e-05 - mae: 0.0033 - val_loss: 1.4633e-05 - val_mae: 0.0032\n",
            "Epoch 236/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4514e-05 - mae: 0.0032 - val_loss: 1.4621e-05 - val_mae: 0.0032\n",
            "Epoch 237/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4357e-05 - mae: 0.0032 - val_loss: 1.6108e-05 - val_mae: 0.0033\n",
            "Epoch 238/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.4384e-05 - mae: 0.0032 - val_loss: 1.3632e-05 - val_mae: 0.0031\n",
            "Epoch 239/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3603e-05 - mae: 0.0031 - val_loss: 1.3486e-05 - val_mae: 0.0031\n",
            "Epoch 240/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3351e-05 - mae: 0.0031 - val_loss: 1.2986e-05 - val_mae: 0.0030\n",
            "Epoch 241/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3010e-05 - mae: 0.0031 - val_loss: 1.2753e-05 - val_mae: 0.0030\n",
            "Epoch 242/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2764e-05 - mae: 0.0030 - val_loss: 1.2583e-05 - val_mae: 0.0030\n",
            "Epoch 243/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2876e-05 - mae: 0.0030 - val_loss: 1.2336e-05 - val_mae: 0.0029\n",
            "Epoch 244/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2393e-05 - mae: 0.0030 - val_loss: 1.2288e-05 - val_mae: 0.0029\n",
            "Epoch 245/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1971e-05 - mae: 0.0029 - val_loss: 1.2691e-05 - val_mae: 0.0029\n",
            "Epoch 246/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1433e-05 - mae: 0.0029 - val_loss: 1.2153e-05 - val_mae: 0.0029\n",
            "Epoch 247/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1586e-05 - mae: 0.0029 - val_loss: 1.1127e-05 - val_mae: 0.0028\n",
            "Epoch 248/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1111e-05 - mae: 0.0028 - val_loss: 1.1830e-05 - val_mae: 0.0028\n",
            "Epoch 249/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1132e-05 - mae: 0.0028 - val_loss: 1.0773e-05 - val_mae: 0.0027\n",
            "Epoch 250/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0786e-05 - mae: 0.0028 - val_loss: 1.0628e-05 - val_mae: 0.0027\n",
            "Epoch 251/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0528e-05 - mae: 0.0027 - val_loss: 1.0297e-05 - val_mae: 0.0027\n",
            "Epoch 252/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0033e-05 - mae: 0.0027 - val_loss: 1.2921e-05 - val_mae: 0.0029\n",
            "Epoch 253/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0390e-05 - mae: 0.0027 - val_loss: 9.8691e-06 - val_mae: 0.0026\n",
            "Epoch 254/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.7396e-06 - mae: 0.0026 - val_loss: 1.0107e-05 - val_mae: 0.0026\n",
            "Epoch 255/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.7640e-06 - mae: 0.0026 - val_loss: 9.5034e-06 - val_mae: 0.0026\n",
            "Epoch 256/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.3782e-06 - mae: 0.0026 - val_loss: 9.7287e-06 - val_mae: 0.0026\n",
            "Epoch 257/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.2585e-06 - mae: 0.0026 - val_loss: 9.1235e-06 - val_mae: 0.0025\n",
            "Epoch 258/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 9.1853e-06 - mae: 0.0026 - val_loss: 8.9254e-06 - val_mae: 0.0025\n",
            "Epoch 259/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 9.1007e-06 - mae: 0.0025 - val_loss: 8.8363e-06 - val_mae: 0.0025\n",
            "Epoch 260/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.7201e-06 - mae: 0.0025 - val_loss: 8.6723e-06 - val_mae: 0.0025\n",
            "Epoch 261/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.6496e-06 - mae: 0.0025 - val_loss: 8.7598e-06 - val_mae: 0.0025\n",
            "Epoch 262/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.3945e-06 - mae: 0.0024 - val_loss: 9.3534e-06 - val_mae: 0.0025\n",
            "Epoch 263/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.3841e-06 - mae: 0.0024 - val_loss: 8.2732e-06 - val_mae: 0.0024\n",
            "Epoch 264/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.2260e-06 - mae: 0.0024 - val_loss: 8.1974e-06 - val_mae: 0.0024\n",
            "Epoch 265/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.9858e-06 - mae: 0.0024 - val_loss: 8.0620e-06 - val_mae: 0.0024\n",
            "Epoch 266/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.8567e-06 - mae: 0.0024 - val_loss: 8.0422e-06 - val_mae: 0.0024\n",
            "Epoch 267/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.6680e-06 - mae: 0.0023 - val_loss: 7.7968e-06 - val_mae: 0.0023\n",
            "Epoch 268/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.5084e-06 - mae: 0.0023 - val_loss: 7.8714e-06 - val_mae: 0.0023\n",
            "Epoch 269/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.5569e-06 - mae: 0.0023 - val_loss: 7.4315e-06 - val_mae: 0.0023\n",
            "Epoch 270/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.3050e-06 - mae: 0.0023 - val_loss: 7.7604e-06 - val_mae: 0.0023\n",
            "Epoch 271/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.2112e-06 - mae: 0.0023 - val_loss: 7.4907e-06 - val_mae: 0.0023\n",
            "Epoch 272/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.2084e-06 - mae: 0.0023 - val_loss: 7.2483e-06 - val_mae: 0.0022\n",
            "Epoch 273/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 7.0671e-06 - mae: 0.0022 - val_loss: 7.1211e-06 - val_mae: 0.0022\n",
            "Epoch 274/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 7.0931e-06 - mae: 0.0022 - val_loss: 7.0656e-06 - val_mae: 0.0022\n",
            "Epoch 275/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.7777e-06 - mae: 0.0022 - val_loss: 7.0499e-06 - val_mae: 0.0022\n",
            "Epoch 276/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.7892e-06 - mae: 0.0022 - val_loss: 6.7082e-06 - val_mae: 0.0022\n",
            "Epoch 277/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.5291e-06 - mae: 0.0022 - val_loss: 6.9989e-06 - val_mae: 0.0022\n",
            "Epoch 278/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.5796e-06 - mae: 0.0022 - val_loss: 6.5606e-06 - val_mae: 0.0021\n",
            "Epoch 279/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.4717e-06 - mae: 0.0021 - val_loss: 6.4505e-06 - val_mae: 0.0021\n",
            "Epoch 280/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.5379e-06 - mae: 0.0022 - val_loss: 6.3281e-06 - val_mae: 0.0021\n",
            "Epoch 281/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.2008e-06 - mae: 0.0021 - val_loss: 6.4858e-06 - val_mae: 0.0021\n",
            "Epoch 282/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.2559e-06 - mae: 0.0021 - val_loss: 6.2658e-06 - val_mae: 0.0021\n",
            "Epoch 283/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.2101e-06 - mae: 0.0021 - val_loss: 6.1919e-06 - val_mae: 0.0021\n",
            "Epoch 284/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 6.0446e-06 - mae: 0.0021 - val_loss: 6.0151e-06 - val_mae: 0.0020\n",
            "Epoch 285/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.8422e-06 - mae: 0.0020 - val_loss: 6.1654e-06 - val_mae: 0.0021\n",
            "Epoch 286/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.8683e-06 - mae: 0.0020 - val_loss: 5.9562e-06 - val_mae: 0.0020\n",
            "Epoch 287/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.8875e-06 - mae: 0.0020 - val_loss: 5.8356e-06 - val_mae: 0.0020\n",
            "Epoch 288/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.7318e-06 - mae: 0.0020 - val_loss: 5.9212e-06 - val_mae: 0.0020\n",
            "Epoch 289/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.6855e-06 - mae: 0.0020 - val_loss: 5.7507e-06 - val_mae: 0.0020\n",
            "Epoch 290/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.4835e-06 - mae: 0.0020 - val_loss: 5.9548e-06 - val_mae: 0.0020\n",
            "Epoch 291/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.5522e-06 - mae: 0.0020 - val_loss: 5.5300e-06 - val_mae: 0.0020\n",
            "Epoch 292/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.4890e-06 - mae: 0.0020 - val_loss: 5.6957e-06 - val_mae: 0.0020\n",
            "Epoch 293/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.3719e-06 - mae: 0.0020 - val_loss: 5.3913e-06 - val_mae: 0.0019\n",
            "Epoch 294/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.3931e-06 - mae: 0.0020 - val_loss: 5.3114e-06 - val_mae: 0.0019\n",
            "Epoch 295/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.2610e-06 - mae: 0.0019 - val_loss: 5.2971e-06 - val_mae: 0.0019\n",
            "Epoch 296/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.1615e-06 - mae: 0.0019 - val_loss: 5.2030e-06 - val_mae: 0.0019\n",
            "Epoch 297/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.1462e-06 - mae: 0.0019 - val_loss: 5.4252e-06 - val_mae: 0.0019\n",
            "Epoch 298/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.0605e-06 - mae: 0.0019 - val_loss: 5.1953e-06 - val_mae: 0.0019\n",
            "Epoch 299/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 5.0423e-06 - mae: 0.0019 - val_loss: 5.1314e-06 - val_mae: 0.0019\n",
            "Epoch 300/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.9276e-06 - mae: 0.0019 - val_loss: 4.9982e-06 - val_mae: 0.0019\n",
            "Epoch 301/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.8909e-06 - mae: 0.0019 - val_loss: 4.9754e-06 - val_mae: 0.0019\n",
            "Epoch 302/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.7400e-06 - mae: 0.0018 - val_loss: 5.4269e-06 - val_mae: 0.0019\n",
            "Epoch 303/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.8366e-06 - mae: 0.0018 - val_loss: 4.8151e-06 - val_mae: 0.0018\n",
            "Epoch 304/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.7436e-06 - mae: 0.0018 - val_loss: 4.9643e-06 - val_mae: 0.0018\n",
            "Epoch 305/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.7314e-06 - mae: 0.0018 - val_loss: 4.8174e-06 - val_mae: 0.0018\n",
            "Epoch 306/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 4.6408e-06 - mae: 0.0018 - val_loss: 4.6729e-06 - val_mae: 0.0018\n",
            "Epoch 307/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.5738e-06 - mae: 0.0018 - val_loss: 4.7072e-06 - val_mae: 0.0018\n",
            "Epoch 308/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.5503e-06 - mae: 0.0018 - val_loss: 4.8674e-06 - val_mae: 0.0018\n",
            "Epoch 309/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.4777e-06 - mae: 0.0018 - val_loss: 4.6652e-06 - val_mae: 0.0018\n",
            "Epoch 310/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 4.4662e-06 - mae: 0.0018 - val_loss: 4.6373e-06 - val_mae: 0.0018\n",
            "Epoch 311/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.4112e-06 - mae: 0.0018 - val_loss: 4.5167e-06 - val_mae: 0.0018\n",
            "Epoch 312/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.3494e-06 - mae: 0.0018 - val_loss: 4.3891e-06 - val_mae: 0.0018\n",
            "Epoch 313/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.2974e-06 - mae: 0.0017 - val_loss: 4.4116e-06 - val_mae: 0.0018\n",
            "Epoch 314/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.2139e-06 - mae: 0.0017 - val_loss: 4.4093e-06 - val_mae: 0.0017\n",
            "Epoch 315/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.2446e-06 - mae: 0.0017 - val_loss: 4.3208e-06 - val_mae: 0.0017\n",
            "Epoch 316/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.1637e-06 - mae: 0.0017 - val_loss: 4.4366e-06 - val_mae: 0.0017\n",
            "Epoch 317/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.1079e-06 - mae: 0.0017 - val_loss: 4.2331e-06 - val_mae: 0.0017\n",
            "Epoch 318/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.1361e-06 - mae: 0.0017 - val_loss: 4.1880e-06 - val_mae: 0.0017\n",
            "Epoch 319/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.0803e-06 - mae: 0.0017 - val_loss: 4.1953e-06 - val_mae: 0.0017\n",
            "Epoch 320/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.0038e-06 - mae: 0.0017 - val_loss: 4.2272e-06 - val_mae: 0.0017\n",
            "Epoch 321/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.0176e-06 - mae: 0.0017 - val_loss: 4.0812e-06 - val_mae: 0.0017\n",
            "Epoch 322/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.9901e-06 - mae: 0.0017 - val_loss: 4.0095e-06 - val_mae: 0.0017\n",
            "Epoch 323/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.9190e-06 - mae: 0.0017 - val_loss: 4.0156e-06 - val_mae: 0.0017\n",
            "Epoch 324/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.8538e-06 - mae: 0.0017 - val_loss: 4.2557e-06 - val_mae: 0.0017\n",
            "Epoch 325/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.8826e-06 - mae: 0.0017 - val_loss: 3.9046e-06 - val_mae: 0.0016\n",
            "Epoch 326/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.8646e-06 - mae: 0.0017 - val_loss: 3.9005e-06 - val_mae: 0.0016\n",
            "Epoch 327/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.7758e-06 - mae: 0.0016 - val_loss: 3.9873e-06 - val_mae: 0.0016\n",
            "Epoch 328/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.7629e-06 - mae: 0.0016 - val_loss: 3.7874e-06 - val_mae: 0.0016\n",
            "Epoch 329/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.7388e-06 - mae: 0.0016 - val_loss: 3.8078e-06 - val_mae: 0.0016\n",
            "Epoch 330/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.6868e-06 - mae: 0.0016 - val_loss: 3.7994e-06 - val_mae: 0.0016\n",
            "Epoch 331/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.6800e-06 - mae: 0.0016 - val_loss: 3.7197e-06 - val_mae: 0.0016\n",
            "Epoch 332/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.6672e-06 - mae: 0.0016 - val_loss: 3.6764e-06 - val_mae: 0.0016\n",
            "Epoch 333/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.6628e-06 - mae: 0.0016 - val_loss: 3.6690e-06 - val_mae: 0.0016\n",
            "Epoch 334/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.5412e-06 - mae: 0.0016 - val_loss: 3.6206e-06 - val_mae: 0.0016\n",
            "Epoch 335/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.5018e-06 - mae: 0.0016 - val_loss: 3.6582e-06 - val_mae: 0.0016\n",
            "Epoch 336/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.4546e-06 - mae: 0.0016 - val_loss: 3.5778e-06 - val_mae: 0.0016\n",
            "Epoch 337/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.4710e-06 - mae: 0.0016 - val_loss: 3.5442e-06 - val_mae: 0.0016\n",
            "Epoch 338/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.4291e-06 - mae: 0.0016 - val_loss: 3.7520e-06 - val_mae: 0.0016\n",
            "Epoch 339/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.4429e-06 - mae: 0.0016 - val_loss: 3.5182e-06 - val_mae: 0.0016\n",
            "Epoch 340/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.3497e-06 - mae: 0.0015 - val_loss: 3.5518e-06 - val_mae: 0.0016\n",
            "Epoch 341/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.3582e-06 - mae: 0.0016 - val_loss: 3.5055e-06 - val_mae: 0.0015\n",
            "Epoch 342/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.3470e-06 - mae: 0.0015 - val_loss: 3.3882e-06 - val_mae: 0.0015\n",
            "Epoch 343/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.2733e-06 - mae: 0.0015 - val_loss: 3.4640e-06 - val_mae: 0.0015\n",
            "Epoch 344/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.2766e-06 - mae: 0.0015 - val_loss: 3.3326e-06 - val_mae: 0.0015\n",
            "Epoch 345/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.2851e-06 - mae: 0.0015 - val_loss: 3.3208e-06 - val_mae: 0.0015\n",
            "Epoch 346/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.2345e-06 - mae: 0.0015 - val_loss: 3.3016e-06 - val_mae: 0.0015\n",
            "Epoch 347/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.2361e-06 - mae: 0.0015 - val_loss: 3.3280e-06 - val_mae: 0.0015\n",
            "Epoch 348/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.1401e-06 - mae: 0.0015 - val_loss: 3.2656e-06 - val_mae: 0.0015\n",
            "Epoch 349/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.1580e-06 - mae: 0.0015 - val_loss: 3.2613e-06 - val_mae: 0.0015\n",
            "Epoch 350/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.1409e-06 - mae: 0.0015 - val_loss: 3.2799e-06 - val_mae: 0.0015\n",
            "Epoch 351/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0223e-06 - mae: 0.0015 - val_loss: 3.1687e-06 - val_mae: 0.0015\n",
            "Epoch 352/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.1180e-06 - mae: 0.0015 - val_loss: 3.1730e-06 - val_mae: 0.0015\n",
            "Epoch 353/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0378e-06 - mae: 0.0015 - val_loss: 3.1484e-06 - val_mae: 0.0015\n",
            "Epoch 354/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0586e-06 - mae: 0.0015 - val_loss: 3.1253e-06 - val_mae: 0.0015\n",
            "Epoch 355/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.0114e-06 - mae: 0.0015 - val_loss: 3.2487e-06 - val_mae: 0.0015\n",
            "Epoch 356/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.0055e-06 - mae: 0.0015 - val_loss: 3.0811e-06 - val_mae: 0.0015\n",
            "Epoch 357/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0062e-06 - mae: 0.0015 - val_loss: 3.0760e-06 - val_mae: 0.0015\n",
            "Epoch 358/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9554e-06 - mae: 0.0014 - val_loss: 3.1200e-06 - val_mae: 0.0015\n",
            "Epoch 359/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.9644e-06 - mae: 0.0015 - val_loss: 3.0385e-06 - val_mae: 0.0014\n",
            "Epoch 360/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.9268e-06 - mae: 0.0014 - val_loss: 3.0369e-06 - val_mae: 0.0014\n",
            "Epoch 361/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8876e-06 - mae: 0.0014 - val_loss: 2.9788e-06 - val_mae: 0.0014\n",
            "Epoch 362/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8613e-06 - mae: 0.0014 - val_loss: 2.9852e-06 - val_mae: 0.0014\n",
            "Epoch 363/400\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8747e-06 - mae: 0.0014 - val_loss: 2.9603e-06 - val_mae: 0.0014\n",
            "Epoch 364/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.8331e-06 - mae: 0.0014 - val_loss: 3.0354e-06 - val_mae: 0.0014\n",
            "Epoch 365/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8275e-06 - mae: 0.0014 - val_loss: 2.9119e-06 - val_mae: 0.0014\n",
            "Epoch 366/400\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8183e-06 - mae: 0.0014 - val_loss: 2.8770e-06 - val_mae: 0.0014\n",
            "Epoch 367/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7824e-06 - mae: 0.0014 - val_loss: 2.9012e-06 - val_mae: 0.0014\n",
            "Epoch 368/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.7761e-06 - mae: 0.0014 - val_loss: 2.8475e-06 - val_mae: 0.0014\n",
            "Epoch 369/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7718e-06 - mae: 0.0014 - val_loss: 2.8269e-06 - val_mae: 0.0014\n",
            "Epoch 370/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7220e-06 - mae: 0.0014 - val_loss: 2.7931e-06 - val_mae: 0.0014\n",
            "Epoch 371/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7090e-06 - mae: 0.0014 - val_loss: 2.7866e-06 - val_mae: 0.0014\n",
            "Epoch 372/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6909e-06 - mae: 0.0014 - val_loss: 2.7936e-06 - val_mae: 0.0014\n",
            "Epoch 373/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.7245e-06 - mae: 0.0014 - val_loss: 2.7635e-06 - val_mae: 0.0014\n",
            "Epoch 374/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6805e-06 - mae: 0.0014 - val_loss: 2.7549e-06 - val_mae: 0.0014\n",
            "Epoch 375/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6049e-06 - mae: 0.0014 - val_loss: 2.7564e-06 - val_mae: 0.0014\n",
            "Epoch 376/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6156e-06 - mae: 0.0014 - val_loss: 2.7024e-06 - val_mae: 0.0014\n",
            "Epoch 377/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5991e-06 - mae: 0.0014 - val_loss: 2.6833e-06 - val_mae: 0.0014\n",
            "Epoch 378/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6026e-06 - mae: 0.0014 - val_loss: 2.6613e-06 - val_mae: 0.0014\n",
            "Epoch 379/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5937e-06 - mae: 0.0014 - val_loss: 2.6413e-06 - val_mae: 0.0014\n",
            "Epoch 380/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5465e-06 - mae: 0.0013 - val_loss: 2.6210e-06 - val_mae: 0.0013\n",
            "Epoch 381/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5181e-06 - mae: 0.0013 - val_loss: 2.6377e-06 - val_mae: 0.0013\n",
            "Epoch 382/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5124e-06 - mae: 0.0013 - val_loss: 2.6317e-06 - val_mae: 0.0013\n",
            "Epoch 383/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.5189e-06 - mae: 0.0013 - val_loss: 2.7289e-06 - val_mae: 0.0014\n",
            "Epoch 384/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5190e-06 - mae: 0.0013 - val_loss: 2.5753e-06 - val_mae: 0.0013\n",
            "Epoch 385/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.4853e-06 - mae: 0.0013 - val_loss: 2.5720e-06 - val_mae: 0.0013\n",
            "Epoch 386/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4977e-06 - mae: 0.0013 - val_loss: 2.6546e-06 - val_mae: 0.0013\n",
            "Epoch 387/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4925e-06 - mae: 0.0013 - val_loss: 2.5253e-06 - val_mae: 0.0013\n",
            "Epoch 388/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4472e-06 - mae: 0.0013 - val_loss: 2.5331e-06 - val_mae: 0.0013\n",
            "Epoch 389/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4212e-06 - mae: 0.0013 - val_loss: 2.5014e-06 - val_mae: 0.0013\n",
            "Epoch 390/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.4278e-06 - mae: 0.0013 - val_loss: 2.4775e-06 - val_mae: 0.0013\n",
            "Epoch 391/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3872e-06 - mae: 0.0013 - val_loss: 2.5835e-06 - val_mae: 0.0013\n",
            "Epoch 392/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4152e-06 - mae: 0.0013 - val_loss: 2.4918e-06 - val_mae: 0.0013\n",
            "Epoch 393/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3885e-06 - mae: 0.0013 - val_loss: 2.4649e-06 - val_mae: 0.0013\n",
            "Epoch 394/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3715e-06 - mae: 0.0013 - val_loss: 2.4432e-06 - val_mae: 0.0013\n",
            "Epoch 395/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3675e-06 - mae: 0.0013 - val_loss: 2.4336e-06 - val_mae: 0.0013\n",
            "Epoch 396/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3551e-06 - mae: 0.0013 - val_loss: 2.4276e-06 - val_mae: 0.0013\n",
            "Epoch 397/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2911e-06 - mae: 0.0013 - val_loss: 2.4986e-06 - val_mae: 0.0013\n",
            "Epoch 398/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.3174e-06 - mae: 0.0013 - val_loss: 2.3766e-06 - val_mae: 0.0013\n",
            "Epoch 399/400\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2901e-06 - mae: 0.0013 - val_loss: 2.3916e-06 - val_mae: 0.0013\n",
            "Epoch 400/400\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.2833e-06 - mae: 0.0013 - val_loss: 2.3457e-06 - val_mae: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65c6c60d-f91e-4411-d996-af87173a80bd"
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "predictions =\n",
            " [[0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.001 0.    0.999]\n",
            " [0.001 0.    0.999]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.    0.998]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.001 0.    0.999]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.998 0.001 0.001]\n",
            " [0.998 0.001 0.001]\n",
            " [0.002 0.    0.998]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.998 0.001 0.001]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.    0.998]\n",
            " [0.001 0.    0.999]\n",
            " [0.002 0.    0.998]\n",
            " [0.001 0.    0.999]\n",
            " [0.998 0.001 0.001]\n",
            " [0.998 0.001 0.001]\n",
            " [0.998 0.    0.001]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.002 0.998 0.   ]]\n",
            "actual =\n",
            " [[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831ff46b-2ac5-4d6c-c404-c57e873581e1"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "\n",
        ""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 2472 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File\n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f047122-d20a-4e6d-dd75-69427f8587b4"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 15,278 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ]
}